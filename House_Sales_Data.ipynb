{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OLS(object):\n",
    "    def __init__(self, beta_true = None):\n",
    "        self.model = LinearRegression()\n",
    "\n",
    "    def fit(self, x, y, **options):\n",
    "        n, p = x.shape\n",
    "        # Set the sample weights\n",
    "        if 'weights' in options:\n",
    "            self.weights = np.reshape(options['weights'], [n,])\n",
    "        else:\n",
    "            self.weights = np.ones([n,])\n",
    "\n",
    "        # Fit the model and get the parameter\n",
    "        self.model.fit(x, y, sample_weight = self.weights)\n",
    "        self.beta = np.reshape(self.model.coef_, [p, 1])\n",
    "        self.intercept = np.reshape(self.model.intercept_, [1, 1])\n",
    "        self.coef = np.concatenate((self.intercept, self.beta), axis = 0)\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        return np.matmul(x_test, self.beta) + self.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_list, Y_list = [], []\n",
    "for i in range(6):\n",
    "    x = np.load('House_Data/X'+str(i)+'.npy')\n",
    "    y = np.load('House_Data/Y'+str(i)+'.npy')\n",
    "    X_list.append(x)\n",
    "    Y_list.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======Envrionment    0============\n",
      "Original Correlation:  0.19463977288355847\n",
      "Original Collinearity:  41.28751156758869\n",
      "======Envrionment    1============\n",
      "Original Correlation:  0.20517168815940565\n",
      "Original Collinearity:  42.333709959295646\n",
      "======Envrionment    2============\n",
      "Original Correlation:  0.19539134384534926\n",
      "Original Collinearity:  34.80208300624458\n",
      "======Envrionment    3============\n",
      "Original Correlation:  0.1844833299748109\n",
      "Original Collinearity:  33.44420625408224\n",
      "======Envrionment    4============\n",
      "Original Correlation:  0.1786383434270527\n",
      "Original Collinearity:  31.203442363271016\n",
      "======Envrionment    5============\n",
      "Original Correlation:  0.16375951007089282\n",
      "Original Collinearity:  31.941753947565097\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    x, y = X_list[i], Y_list[i]\n",
    "    w_stat = weighted_stat(x, np.ones(y.shape))\n",
    "    # default by indentity.\n",
    "    print('======Envrionment %4d============' % (i))\n",
    "    print('Original Correlation: ', w_stat['mean_corr'])\n",
    "    print('Original Collinearity: ', w_stat['CN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "train_ind = 0\n",
    "x_train_whole, y_train_whole = X_list[train_ind], Y_list[train_ind]\n",
    "sample_index = np.random.choice(x_train_whole.shape[0], 500, replace=False)\n",
    "unsample_index = [x for x in range(len(x_train_whole)) if not (x in sample_index)]\n",
    "\n",
    "x_train, y_train = x_train_whole[sample_index], y_train_whole[sample_index]\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_iid_test, y_iid_test = scaler.transform(x_train_whole[unsample_index]), y_train_whole[unsample_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Correlation:  0.2170941630425216\n",
      "Original Collinearity:  51.51486885287824\n"
     ]
    }
   ],
   "source": [
    "w_stat = weighted_stat(x_train_scaled, np.ones(y_train.shape))\n",
    "print('Original Correlation: ', w_stat['mean_corr'])\n",
    "print('Original Collinearity: ', w_stat['CN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols = OLS()\n",
    "ols.fit(x_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_ols = []\n",
    "for i in range(6):\n",
    "    if i == train_ind:\n",
    "        x_test, y_test = x_iid_test, y_iid_test\n",
    "    else:\n",
    "        x_test, y_test = scaler.transform(X_list[i]), Y_list[i]\n",
    "    rmse_ols.append(cal_prediction_error(y_test, ols.predict(x_test), 'rmse'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ave_RMSE(std) of OLS: 365078.1571(137313.6264)\n"
     ]
    }
   ],
   "source": [
    "print('ave_RMSE(std) of OLS: %.4f(%.4f)'%(np.mean(rmse_ols), np.std(rmse_ols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def column_wise_resampling(x, replacement = False, random_state = 0, **options):\n",
    "    \"\"\"\n",
    "    Perform column-wise random resampling to break the joint distribution of p(x).\n",
    "    In practice, we can perform resampling without replacement (a.k.a. permutation) to retain all the data points of feature x_j. \n",
    "    Moreover, if the practitioner has some priors on which features should be permuted,\n",
    "    it can be passed through options by specifying 'sensitive_variables', by default it contains all the features\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    n, p = x.shape\n",
    "    if 'sensitive_variables' in options:\n",
    "        sensitive_variables = options['sensitive_variables']\n",
    "    else:\n",
    "        sensitive_variables = [i for i in range(p)] \n",
    "    x_decorrelation = np.zeros([n, p])\n",
    "    for i in sensitive_variables:\n",
    "        var = x[:, i]\n",
    "        if replacement: # sampling with replacement\n",
    "            x_decorrelation[:, i] = np.array([var[rng.randint(0, n)] for j in range(n)])\n",
    "        else: # permutation     \n",
    "            x_decorrelation[:, i] = var[rng.permutation(n)]\n",
    "    return x_decorrelation\n",
    "\n",
    "def decorrelation(x, solver = 'adam', hidden_layer_sizes = (2,), max_iter = 500, random_state = 0, clip_range = 0.9):\n",
    "    \"\"\"\n",
    "    Calcualte new sample weights by density ratio estimation\n",
    "           q(x)   P(x belongs to q(x) | x) \n",
    "    w(x) = ---- = ------------------------ \n",
    "           p(x)   P(x belongs to p(x) | x)\n",
    "\n",
    "    If default == True, then a single hidden layer perceptron will be used as binary classifier, \n",
    "    otherwise you can specify it by 'classifier', it must have 'fit' and 'predict_proba' api according to sklearn API standard.\n",
    "    \"\"\"\n",
    "    n, p = x.shape\n",
    "    x_decorrelation = column_wise_resampling(x, random_state = random_state)\n",
    "    P = pd.DataFrame(x)\n",
    "    Q = pd.DataFrame(x_decorrelation)\n",
    "    P['src'] = 1 # 1 means source distribution\n",
    "    Q['src'] = 0 # 0 means target distribution\n",
    "    Z = pd.concat([P, Q], ignore_index=True, axis=0)\n",
    "    labels = Z['src'].values\n",
    "    Z = Z.drop('src', axis=1).values\n",
    "    P, Q = P.values, Q.values\n",
    "\n",
    "    # Train a binary classifier to classify the source and target distribution\n",
    "    clf = MLPClassifier(solver=solver, hidden_layer_sizes=hidden_layer_sizes, max_iter=max_iter, random_state=random_state)\n",
    "    clf.fit(Z, labels)\n",
    "    proba = np.clip(clf.predict_proba(Z)[:len(P), 1], 1-clip_range, clip_range)\n",
    "    weights = (1./proba) - 1. # calculate sample weights by density ratio\n",
    "    weights /= np.mean(weights) # normalize the weights to get average 1\n",
    "    weights = np.reshape(weights, [n,])\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decorrelated Correlation:  0.15337498374949854\n",
      "Decorrelated Collinearity:  17.197719725581518\n",
      "Start fitting\n",
      "ave_RMSE(std) of OLS+Our: 249206.1521(47224.5792)\n"
     ]
    }
   ],
   "source": [
    "ols_our = OLS()\n",
    "w = decorrelation(x_train_scaled, max_iter=1000, hidden_layer_sizes=(3,))\n",
    "w_stat = weighted_stat(x_train_scaled, w)\n",
    "print('Decorrelated Correlation: ', w_stat['mean_corr'])\n",
    "print('Decorrelated Collinearity: ', w_stat['CN'])\n",
    "print('Start fitting')\n",
    "\n",
    "ols_our.fit(x_train_scaled, y_train, weights=w)\n",
    "rmse_ols_our = []\n",
    "for i in range(6):\n",
    "    if i == train_ind:\n",
    "        x_test, y_test = x_iid_test, y_iid_test\n",
    "    else:\n",
    "        x_test, y_test = scaler.transform(X_list[i]), Y_list[i]\n",
    "    rmse_ols_our.append(cal_prediction_error(y_test, ols_our.predict(x_test)))\n",
    "\n",
    "print('ave_RMSE(std) of OLS+Our: %.4f(%.4f)'%(np.mean(rmse_ols_our), np.std(rmse_ols_our)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "0496842fed3252e429d236fd9df9f28ef62eb2f8e7d98cd38ba8d6755488d983"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
