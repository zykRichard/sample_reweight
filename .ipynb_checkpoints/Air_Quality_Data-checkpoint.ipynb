{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%matplotlib inline\n",
    "%run ./code/package_loader.py\n",
    "%aimport data_generator, model, baseline, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_x, p_y = 6, 6\n",
    "file_name_list = ['AQ-01-073-0023','AQ-09-009-0027','AQ-11-001-0043',\n",
    "                  'AQ-13-089-0002','AQ-18-097-0078','AQ-22-033-0009',\n",
    "                  'AQ-35-001-0023','AQ-37-119-0041','AQ-39-061-0040','AQ-56-021-0100']\n",
    "state_X_list, state_Y_list = [], []\n",
    "for file_name in file_name_list:\n",
    "    fd = open('AQ_data/'+file_name+'.csv', 'r')\n",
    "    data = fd.readlines()\n",
    "    x, y = np.zeros((len(data), p_x)), np.zeros((len(data), p_y))\n",
    "    for ind, line in enumerate(data):\n",
    "        temp = line.strip().split(',')\n",
    "        x[ind, :] = [i for i in map(float, temp[:p_x])]\n",
    "        y[ind, :] = [i for i in map(float, temp[p_x:])]\n",
    "    state_X_list.append(x); state_Y_list.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    x_train, y_train = state_X_list[i], state_Y_list[i]\n",
    "    _, correlation, collinearity = weighted_corrcoef(x_train, np.ones((x_train.shape[0], 1)))\n",
    "    print('Original Correlation: ', correlation)\n",
    "    print('Original Collinearity: ', collinearity)\n",
    "    features = ['temp', 'pressure', 'humidity', 'dir_sin', 'dir_cos', 'speed']\n",
    "    corrmat = np.corrcoef(x_train, rowvar = False)\n",
    "    f, ax = plt.subplots(figsize=(10, 7))\n",
    "    plt.xticks(rotation='45')\n",
    "    sns.heatmap(corrmat, annot=True, square=True, linewidths=.5,\n",
    "                xticklabels=features, yticklabels=features, cmap='YlGnBu')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ind = 1\n",
    "outcome_ind = 3\n",
    "x_train_whole, y_train_whole = state_X_list[train_ind], state_Y_list[train_ind][:, outcome_ind]\n",
    "# Sample and Scale the data\n",
    "np.random.seed(0)\n",
    "sample_index = np.random.choice(x_train_whole.shape[0], 500, replace=False)\n",
    "unsample_index = [x for x in range(len(x_train_whole)) if not (x in sample_index)]\n",
    "\n",
    "x_train, y_train = x_train_whole[sample_index], y_train_whole[sample_index]\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_iid_test, y_iid_test = scaler.transform(x_train_whole[unsample_index]), y_train_whole[unsample_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Correlation:  0.34681692111845663\n",
      "Original Collinearity:  5.34104867812108\n"
     ]
    }
   ],
   "source": [
    "_, correlation, collinearity = weighted_corrcoef(x_train_scaled, np.ones((x_train_scaled.shape[0], 1)))\n",
    "print('Original Correlation: ', correlation)\n",
    "print('Original Collinearity: ', collinearity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Lasso & OLS & IILasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols = OLS()\n",
    "coef_ols = ols.fit(x_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.836     ],\n",
       "       [-1.97330217],\n",
       "       [ 0.42385567],\n",
       "       [-0.85789338],\n",
       "       [-0.32341809],\n",
       "       [-2.91460411],\n",
       "       [-2.23240732]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.72360712673791\n"
     ]
    }
   ],
   "source": [
    "print(cal_prediction_error(y_iid_test, ols.predict(x_iid_test), 'rmse'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=False, random_state=0)\n",
    "lasso = Lasso()\n",
    "lambda_list = [x for x in np.logspace(-4, 1, 100)]\n",
    "mse_lasso_cv = np.zeros((len(lambda_list) , 1))\n",
    "\n",
    "for train_index, test_index in kf.split(x_train):\n",
    "    scaler_cv = preprocessing.StandardScaler().fit(x_train[train_index])\n",
    "    x_cvtrain_scaled = scaler_cv.transform(x_train[train_index])\n",
    "    x_cvtest_scaled = scaler_cv.transform(x_train[test_index])\n",
    "    for ind, lambdau in enumerate(lambda_list):\n",
    "        _ = lasso.fit(x_cvtrain_scaled, y_train[train_index], validation=False, lambdau=lambdau, standardize=False)\n",
    "        mse_lasso_cv[ind, 0] += cal_prediction_error(y_train[test_index], lasso.predict(x_cvtest_scaled), 'rmse')\n",
    "        \n",
    "param_index = np.argmin(mse_lasso_cv)\n",
    "lambda_lasso = lambda_list[param_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Lambda for Lasso: 3.1257\n",
      "MSE of Lasso:  8.811123665657538\n",
      "[[10.836]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]\n",
      " [ 0.   ]]\n"
     ]
    }
   ],
   "source": [
    "print('Optimal Lambda for Lasso: %.4f' % (lambda_lasso))\n",
    "coef_lasso = lasso.fit(x_train_scaled, y_train, validation=False, lambdau=lambda_lasso)\n",
    "print('MSE of Lasso: ', cal_prediction_error(y_iid_test, lasso.predict(x_iid_test), 'rmse'))\n",
    "print(coef_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "iilasso = IIlasso()\n",
    "lasso = Lasso()\n",
    "\n",
    "#l1_norm_list = [1e-3, 1e-2, 1e-1, 1, 10]\n",
    "l1_norm_list  = [x for x in np.logspace(-5, -2, 100)]\n",
    "corr_norm_list = [1e-3, 1e-2, 1e-1, 1, 10]\n",
    "mse_iilasso_cv = np.zeros((len(l1_norm_list) , len(corr_norm_list)))\n",
    "mse_lasso_cv = np.zeros((len(l1_norm_list) , 1))\n",
    "val_count = 0\n",
    "\n",
    "for indx, l1_norm in enumerate(l1_norm_list):\n",
    "        _ = lasso.fit(x_train_scaled, y_train, validation=False, lambdau=l1_norm, weights=w_opt)\n",
    "        mse_lasso_cv[indx, 0] += (cal_prediction_error(y_iid_test,  lasso.predict(x_iid_test), 'mse'))\n",
    "\n",
    "# for train_index, test_index in kf.split(x_train_scaled):\n",
    "#     val_count += 1\n",
    "#     #scaler = preprocessing.StandardScaler().fit(x_train[train_index])\n",
    "#     #x_cvtrain_scaled = scaler.transform(x_train[train_index])\n",
    "#     #x_cvtest_scaled = scaler.transform(x_train[test_index])\n",
    "#     for indx, l1_norm in enumerate(l1_norm_list):\n",
    "#         _ = lasso.fit(x_train_scaled[train_index], y_train[train_index], validation=False, lambdau=l1_norm)\n",
    "#         #lasso.beta, lasso.intercept = coef_ols[1:], coef_ols[0]\n",
    "#         mse_lasso_cv[indx, 0] += (cal_prediction_error(y_train[test_index],  lasso.predict(x_train_scaled[test_index]), 'mse'))\n",
    "#     for indx, l1_norm in enumerate(l1_norm_list):\n",
    "#         for indy, corr_norm in enumerate(corr_norm_list):\n",
    "#             _ = iilasso.fit(x_cvtrain_scaled, y_train[train_index].reshape([400,1]), learning_rate=1e-2,\n",
    "#                             l1_norm=l1_norm, corr_norm=corr_norm, model_path='AQ_data')\n",
    "#             mse_iilasso_cv[indx, indy] += cal_prediction_error(y_train[test_index], \n",
    "#                                                     iilasso.predict(x_cvtest_scaled), 'mse')\n",
    "# index = np.argmin(mse_iilasso_cv)\n",
    "# indx, indy = index//len(corr_norm_list), index%len(corr_norm_list)\n",
    "# l1_norm, corr_norm = l1_norm_list[indx], corr_norm_list[indy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.000357  ],\n",
       "       [0.00035698],\n",
       "       [0.00035695],\n",
       "       [0.00035693],\n",
       "       [0.0003569 ],\n",
       "       [0.00035687],\n",
       "       [0.00035684],\n",
       "       [0.00035681],\n",
       "       [0.00035677],\n",
       "       [0.00035673],\n",
       "       [0.00035669],\n",
       "       [0.00035665],\n",
       "       [0.0003566 ],\n",
       "       [0.00035655],\n",
       "       [0.0003565 ],\n",
       "       [0.00035644],\n",
       "       [0.00035638],\n",
       "       [0.00035631],\n",
       "       [0.00035624],\n",
       "       [0.00035616],\n",
       "       [0.00035608],\n",
       "       [0.00035599],\n",
       "       [0.0003559 ],\n",
       "       [0.00035579],\n",
       "       [0.00035569],\n",
       "       [0.00035557],\n",
       "       [0.00035545],\n",
       "       [0.00035531],\n",
       "       [0.00035517],\n",
       "       [0.00035502],\n",
       "       [0.00035485],\n",
       "       [0.00035468],\n",
       "       [0.00035449],\n",
       "       [0.00035429],\n",
       "       [0.00035408],\n",
       "       [0.00035385],\n",
       "       [0.0003536 ],\n",
       "       [0.00035334],\n",
       "       [0.00035306],\n",
       "       [0.00035275],\n",
       "       [0.00035243],\n",
       "       [0.00035209],\n",
       "       [0.00035172],\n",
       "       [0.00035133],\n",
       "       [0.00035091],\n",
       "       [0.00035046],\n",
       "       [0.00034998],\n",
       "       [0.00034947],\n",
       "       [0.00034893],\n",
       "       [0.00034835],\n",
       "       [0.00034773],\n",
       "       [0.00034707],\n",
       "       [0.00034637],\n",
       "       [0.00034562],\n",
       "       [0.00034483],\n",
       "       [0.00034399],\n",
       "       [0.00034309],\n",
       "       [0.00034214],\n",
       "       [0.00034114],\n",
       "       [0.00034003],\n",
       "       [0.00033881],\n",
       "       [0.00033751],\n",
       "       [0.00033613],\n",
       "       [0.00033467],\n",
       "       [0.00033311],\n",
       "       [0.00033147],\n",
       "       [0.00032974],\n",
       "       [0.0003279 ],\n",
       "       [0.00032597],\n",
       "       [0.00032393],\n",
       "       [0.00032179],\n",
       "       [0.00031954],\n",
       "       [0.00031719],\n",
       "       [0.00031473],\n",
       "       [0.00031217],\n",
       "       [0.00030951],\n",
       "       [0.00030675],\n",
       "       [0.00030391],\n",
       "       [0.000301  ],\n",
       "       [0.00029802],\n",
       "       [0.00029501],\n",
       "       [0.00029198],\n",
       "       [0.00028893],\n",
       "       [0.00028589],\n",
       "       [0.0002829 ],\n",
       "       [0.00027998],\n",
       "       [0.00027711],\n",
       "       [0.00027428],\n",
       "       [0.00027153],\n",
       "       [0.00026882],\n",
       "       [0.00026617],\n",
       "       [0.00026365],\n",
       "       [0.00026129],\n",
       "       [0.00025918],\n",
       "       [0.00025738],\n",
       "       [0.00025598],\n",
       "       [0.00025508],\n",
       "       [0.00025469],\n",
       "       [0.00025468],\n",
       "       [0.00025468]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_lasso_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.01, 0.001)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_norm, corr_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_iilasso = iilasso.fit(x_train_scaled, y_train.reshape([500,1]), learning_rate=1e-2,\n",
    "                            l1_norm=l1_norm, corr_norm=corr_norm, model_path='AQ_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.039976  ],\n",
       "       [-0.0000986 ],\n",
       "       [ 0.00301105],\n",
       "       [ 0.00043764],\n",
       "       [ 0.00185843],\n",
       "       [ 0.00486853],\n",
       "       [-0.00212519]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_iilasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_ols, mse_lasso, mse_iilasso = [], [], []\n",
    "for i in range(10):\n",
    "    if i == train_ind:\n",
    "        x_test, y_test = x_iid_test, y_iid_test\n",
    "    else:\n",
    "        x_test, y_test = scaler.transform(state_X_list[i]), state_Y_list[i][:, outcome_ind]\n",
    "    mse_ols.append(cal_prediction_error(y_test, ols.predict(x_test), 'rmse'))\n",
    "    mse_lasso.append(cal_prediction_error(y_test, lasso.predict(x_test), 'rmse'))\n",
    "    mse_iilasso.append(cal_prediction_error(y_test, lasso.intercept, 'rmse'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ave_MSE(std) of OLS: 49.0445(17.4258)\n",
      "ave_MSE(std) of Lasso: 12.3232(2.3422)\n",
      "ave_MSE(std) of IILasso: 12.3272(2.3438)\n"
     ]
    }
   ],
   "source": [
    "print('ave_MSE(std) of OLS: %.4f(%.4f)'%(np.mean(mse_ols), np.std(mse_ols)))\n",
    "print('ave_MSE(std) of Lasso: %.4f(%.4f)'%(np.mean(mse_lasso), np.std(mse_lasso)))\n",
    "print('ave_MSE(std) of IILasso: %.4f(%.4f)'%(np.mean(mse_iilasso), np.std(mse_iilasso)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Our Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_list = [1, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "data_description = 'investigate convergence property with different lr'\n",
    "corr_list, coll_list = [], []\n",
    "for learning_rate in learning_rate_list:\n",
    "    log_name = 'AQ_lr_%.0e' % (learning_rate)\n",
    "    w_opt, corr, coll = variable_decorrelation(x = x_train_scaled, y = y_train, \n",
    "                           log_name = log_name, data_description = data_description,\n",
    "                           learning_rate = learning_rate, max_iter = 15000, display_iter=300)\n",
    "    corr_list.append(corr); coll_list.append(coll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 2e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 CV on x_train_scaled for tuning parameter weight_l2 using OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=False, random_state=0)\n",
    "ols, lasso =  OLS(), Lasso()\n",
    "weight_l2_list = [1e-1, 1, 10, 30, 50, 100, 300, 500]\n",
    "mse_l2_list = np.zeros((5, len(weight_l2_list)))\n",
    "mse_ols, mse_lasso = [], []\n",
    "val_count = 0\n",
    "for train_index, test_index in kf.split(x_train):\n",
    "    val_count += 1\n",
    "    x_cvtrain, y_cvtrain = x_train[train_index], y_train[train_index]\n",
    "    x_cvtest, y_cvtest = x_train[test_index], y_train[test_index]\n",
    "    \n",
    "    scaler_cv = preprocessing.StandardScaler().fit(x_cvtrain)\n",
    "    x_cvtrain_scaled = scaler_cv.transform(x_cvtrain)\n",
    "    x_cvtest_scaled = scaler_cv.transform(x_cvtest)\n",
    "    \n",
    "    _ = ols.fit(x_cvtrain_scaled, y_cvtrain)\n",
    "    mse_ols.append(cal_prediction_error(y_cvtest, ols.predict(x_cvtest_scaled), 'mse'))\n",
    "    _ = lasso.fit(x_cvtrain_scaled, y_cvtrain, validation=False, lambdau = 0.23130281)\n",
    "    mse_lasso.append(cal_prediction_error(y_cvtest, lasso.predict(x_cvtest_scaled), 'mse'))\n",
    "#     for ind, weight_l2 in enumerate(weight_l2_list):\n",
    "#         log_name = 'AQ_cv_%d_l2_%.0e' % (val_count, weight_l2)\n",
    "#         w_opt = load_weight(x_cvtrain_scaled, 'model/'+log_name+'/model_iters15000.ckpt')\n",
    "#         _, corr, coll = weighted_corrcoef(x_cvtrain_scaled, w_opt)\n",
    "#         print(corr, coll)\n",
    "# #         w_opt, _, _ = variable_decorrelation(x = x_cvtrain_scaled, y = y_cvtrain, \n",
    "# #                     log_name = log_name, learning_rate = learning_rate, weight_l2 = weight_l2, \n",
    "# #                     max_iter = 15000, max_to_keep = 5)\n",
    "#         _ = ols.fit(x_cvtrain_scaled, y_cvtrain, sample_weight = np.squeeze(w_opt))\n",
    "#         mse_l2_list[val_count-1, ind] = cal_prediction_error(y_cvtest, ols.predict(x_cvtest_scaled), 'rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "448.71122242001684"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mse_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17.38      ],\n",
       "       [ 2.05839841],\n",
       "       [ 0.71298598],\n",
       "       [ 0.        ],\n",
       "       [ 0.72562565],\n",
       "       [-1.18739996],\n",
       "       [ 4.69488758]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2 1e-01: 17.0907(10.3262)\n",
      "l2 1e+00: 17.0909(10.3260)\n",
      "l2 1e+01: 17.0929(10.3234)\n",
      "l2 3e+01: 17.0974(10.3180)\n",
      "l2 5e+01: 17.1016(10.3133)\n",
      "l2 1e+02: 17.1098(10.3044)\n",
      "l2 3e+02: 17.0966(10.3083)\n",
      "l2 5e+02: 17.0872(10.3167)\n",
      "16.99451977856486 10.5326259538568\n"
     ]
    }
   ],
   "source": [
    "for ind, weight_l2 in enumerate(weight_l2_list):\n",
    "    print('l2 %.0e: %.4f(%.4f)' % (weight_l2, np.mean(mse_l2_list[:, ind]), np.std(mse_l2_list[:, ind])))\n",
    "print(np.mean(mse_ols), np.std(mse_ols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_l2 = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Evaluate the performance over different states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_description = 'air quality data'\n",
    "log_name = 'AQ_data'\n",
    "w_opt, correlation, collinearity = variable_decorrelation(x = x_train_scaled, y = y_train, \n",
    "                                    log_name = log_name, learning_rate = learning_rate, weight_l2 = weight_l2,\n",
    "                                    max_iter = 30000, display_iter = 300, max_to_keep = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/AQ_data/model_iters30000.ckpt\n"
     ]
    }
   ],
   "source": [
    "w_opt = load_weight(x_train_scaled, 'model/AQ_data/model_iters30000.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=20, shuffle=False, random_state=0)\n",
    "lasso_our = Lasso()\n",
    "lambda_list = [x for x in np.logspace(-4, 1, 100)]\n",
    "mse_lasso_our_cv = np.zeros((len(lambda_list) , 1))\n",
    "\n",
    "for train_index, test_index in kf.split(x_train):\n",
    "    scaler_cv = preprocessing.StandardScaler().fit(x_train[train_index])\n",
    "    x_cvtrain_scaled = scaler_cv.transform(x_train[train_index])\n",
    "    x_cvtest_scaled = scaler_cv.transform(x_train[test_index])\n",
    "    for ind, lambdau in enumerate(lambda_list):\n",
    "        _ = lasso_our.fit(x_cvtrain_scaled, y_train[train_index], validation=False, lambdau=lambdau, weights=w_opt[train_index])\n",
    "        mse_lasso_our_cv[ind, 0] += cal_prediction_error(y_train[test_index], lasso_our.predict(x_cvtest_scaled), 'mse')\n",
    "        \n",
    "param_index = np.argmin(mse_lasso_our_cv)\n",
    "lambda_lasso_our = lambda_list[param_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Lambda for Lasso+Our: 7.9248\n",
      "MSE of Lasso:  16.9839880191341\n",
      "[[19.40479739]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.76548085]]\n"
     ]
    }
   ],
   "source": [
    "print('Optimal Lambda for Lasso+Our: %.4f' % (lambda_lasso_our))\n",
    "coef_lasso_our = lasso_our.fit(x_train_scaled, y_train, validation=False, lambdau=lambda_lasso_our, weights=w_opt)\n",
    "print('MSE of Lasso: ', cal_prediction_error(y_iid_test, lasso_our.predict(x_iid_test), 'rmse'))\n",
    "print(coef_lasso_our)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_our = OLS()\n",
    "mse_lasso_our, mse_ols_our = [], []\n",
    "coef_ols_our = ols_our.fit(x_train_scaled, y_train, sample_weight=np.squeeze(w_opt))\n",
    "#coef_lasso_our = lasso_our.fit(x_train_scaled, y_train, weights = w_opt, validation=False, lambdau=1e-2)\n",
    "for i in range(10):\n",
    "    if i == train_ind:\n",
    "        x_test, y_test = x_iid_test, y_iid_test\n",
    "    else:\n",
    "        x_test, y_test = scaler.transform(state_X_list[i]), state_Y_list[i][:, outcome_ind]\n",
    "    mse_ols_our.append(cal_prediction_error(y_test, ols_our.predict(x_test), 'rmse'))\n",
    "    mse_lasso_our.append(cal_prediction_error(y_test, lasso_our.predict(x_test), 'rmse'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ave_MSE(std) of OLS+Our: 45.3853(15.2347)\n",
      "ave_MSE(std) of Lasso+OUr: 12.5967(2.3305)\n"
     ]
    }
   ],
   "source": [
    "print('ave_MSE(std) of OLS+Our: %.4f(%.4f)'%(np.mean(mse_ols_our), np.std(mse_ols_our)))\n",
    "print('ave_MSE(std) of Lasso+OUr: %.4f(%.4f)'%(np.mean(mse_lasso_our), np.std(mse_lasso_our)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.31885339]\n",
      " [-0.01548832]\n",
      " [-0.00682469]\n",
      " [ 0.00110986]\n",
      " [-0.0018158 ]\n",
      " [-0.04458581]\n",
      " [-0.03589299]] [[ 0.31907504]\n",
      " [-0.0174633 ]\n",
      " [-0.00879334]\n",
      " [ 0.0014017 ]\n",
      " [-0.00396649]\n",
      " [-0.04693366]\n",
      " [-0.03807552]]\n"
     ]
    }
   ],
   "source": [
    "print(coef_lasso_our, coef_ols_our)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
