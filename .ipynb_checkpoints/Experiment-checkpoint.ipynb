{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter setup to expand cell display to 100% width on your screen (optional)\n",
    "from IPython.core.display import display, HTML\n",
    "#display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable autoreload for customized module and some global settings\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%matplotlib inline\n",
    "#np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, argparse, os, sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy, importlib, pprint, matplotlib.pyplot as plt, warnings\n",
    "import seaborn as sns\n",
    "import glmnet_python\n",
    "from glmnet import glmnet; from glmnetPlot import glmnetPlot\n",
    "from glmnetPrint import glmnetPrint; from glmnetCoef import glmnetCoef; from glmnetPredict import glmnetPredict\n",
    "from cvglmnet import cvglmnet; from cvglmnetCoef import cvglmnetCoef\n",
    "from cvglmnetPlot import cvglmnetPlot; from cvglmnetPredict import cvglmnetPredict\n",
    "from statsmodels.stats.weightstats import DescrStatsW\n",
    "from glmnetSet import glmnetSet\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package need to be reloaded frequently\n",
    "sys.path.append('./code')\n",
    "%aimport data_generator, baseline\n",
    "from data_generator import generate_toy_example\n",
    "from data_generator import linear_model_generation\n",
    "from data_generator import generate_group_data\n",
    "from baseline import Lasso\n",
    "%aimport model, utils\n",
    "from model import variable_decorrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Assumption\n",
    "In the whole experiment, we assume the outcome $Y$ and design matrix $X$ satisfy a linear relationship as follow:\n",
    "\n",
    "$$Y = X\\beta + \\epsilon$$\n",
    "\n",
    "where, $\\epsilon\\sim N(0,noise\\_level^{2})$ is a guassian noise with tunable noise level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Exp1 - Toy Example\n",
    "Assume design matrix $X$ consists of two variables $X_1, X_2$\n",
    "\n",
    "$X_1\\sim N(0,1)$ and $X_2 = X_1 + N(0, decay^{2})$, where smaller $decay$ indicate larger correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们会从$\\beta_2$和$\\beta_3$两种设定比较我们的方法和各种baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Decorrelation with $l_2$ penalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "decay_list = [0.001, 0.01, 0.02, 0.03, 0.04, 0.06, 0.08, 0.1, 0.2, 1]\n",
    "param_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decay 0.001, optimal hyperpara: lr: 3e-3, l2: 5e-4, 90k iter \n",
    "decay = 0.001\n",
    "learning_rate, weight_l2, weight_upper = 3e-3, 5e-4, 0\n",
    "X_toy = generate_toy_example(sample_size=1000, decay=decay)\n",
    "Y_toy = linear_model_generation(X_toy, beta_true)\n",
    "log_name = 'toy_decay_%.0e_l2_%.0e_lr_%.0e' % (decay, weight_l2, learning_rate)\n",
    "data_description = 'Toy data with decay %.0e' % (decay)\n",
    "variable_decorrelation(x = X_toy, y = Y_toy, log_name = log_name, data_description = data_description,\n",
    "                   learning_rate = learning_rate, weight_l2 = weight_l2, weight_upper = weight_upper, \n",
    "                   max_iter = 90000, display_iter=300, save_iter=4500, mode='rotation')\n",
    "######### Complete Tuning ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\"lr\": 3e-3, \"l2\":5e-4, \"iter\":90000}\n",
    "param_list.append(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decay 0.01, optimal hyperpara: lr: 3e-3, l2: 5e-4, 90k iter\n",
    "decay = 0.01\n",
    "learning_rate, weight_l2, weight_upper = 3e-3, 5e-4, 0\n",
    "X_toy = generate_toy_example(sample_size=1000, decay=decay)\n",
    "Y_toy = linear_model_generation(X_toy, beta_true)\n",
    "log_name = 'toy_decay_%.0e_l2_%.0e_lr_%.0e' % (decay, weight_l2, learning_rate)\n",
    "data_description = 'Toy data with decay %.0e' % (decay)\n",
    "variable_decorrelation(x = X_toy, y = Y_toy, log_name = log_name, data_description = data_description,\n",
    "                   learning_rate = learning_rate, weight_l2 = weight_l2, weight_upper = weight_upper, \n",
    "                   max_iter = 90000, display_iter=300, save_iter=4500, mode='rotation')\n",
    "######### Complete Tuning ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\"lr\": 3e-3, \"l2\":5e-4, \"iter\":90000}\n",
    "param_list.append(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decay 0.02, optimal hyperpara: lr: 3e-3, l2: 1e-3, 30k iter + 30k(finetune) \n",
    "decay = 0.02\n",
    "learning_rate, weight_l2, weight_upper = 3e-3, 1e-3, 0\n",
    "X_toy = generate_toy_example(sample_size=1000, decay=decay)\n",
    "Y_toy = linear_model_generation(X_toy, beta_true)\n",
    "log_name = 'toy_decay_%.0e_l2_%.0e_lr_%.0e' % (decay, weight_l2, learning_rate)\n",
    "data_description = 'Toy data with decay %.0e' % (decay)\n",
    "model_path = 'model/toy_decay_%.0e_l2_%.0e_lr_%.0e/model_iters30000.ckpt' % (decay, weight_l2, learning_rate)\n",
    "variable_decorrelation(x = X_toy, y = Y_toy, log_name = log_name, data_description = data_description,\n",
    "                   learning_rate = learning_rate, weight_l2 = weight_l2, weight_upper = weight_upper, \n",
    "                   max_iter = 30000, display_iter=300, save_iter=1500, mode='rotation', model_path=model_path)\n",
    "######### Complete Tuning ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\"lr\": 3e-3, \"l2\":1e-3, \"iter\":30000}\n",
    "param_list.append(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decay 0.03, optimal hyperpara: lr: 3e-3, l2: 2e-3, 30k iter\n",
    "decay = 0.03\n",
    "learning_rate, weight_l2, weight_upper = 3e-3, 2e-3, 0\n",
    "X_toy = generate_toy_example(sample_size=1000, decay=decay)\n",
    "Y_toy = linear_model_generation(X_toy, beta_true)\n",
    "log_name = 'toy_decay_%.0e_l2_%.0e_lr_%.0e' % (decay, weight_l2, learning_rate)\n",
    "data_description = 'Toy data with decay %.0e' % (decay)\n",
    "variable_decorrelation(x = X_toy, y = Y_toy, log_name = log_name, data_description = data_description,\n",
    "                   learning_rate = learning_rate, weight_l2 = weight_l2, weight_upper = weight_upper, \n",
    "                   max_iter = 30000, display_iter=300, save_iter=1500, mode='rotation')\n",
    "######### Complete Tuning ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\"lr\": 3e-3, \"l2\":2e-3, \"iter\":30000}\n",
    "param_list.append(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decay 0.04, optimal hyperpara: lr: 3e-3, l2: 3e-3, 30k iter\n",
    "decay = 0.04\n",
    "learning_rate, weight_l2, weight_upper = 3e-3, 3e-3, 0\n",
    "X_toy = generate_toy_example(sample_size=1000, decay=decay)\n",
    "Y_toy = linear_model_generation(X_toy, beta_true)\n",
    "log_name = 'toy_decay_%.0e_l2_%.0e_lr_%.0e' % (decay, weight_l2, learning_rate)\n",
    "data_description = 'Toy data with decay %.0e' % (decay)\n",
    "variable_decorrelation(x = X_toy, y = Y_toy, log_name = log_name, data_description = data_description,\n",
    "                   learning_rate = learning_rate, weight_l2 = weight_l2, weight_upper = weight_upper, \n",
    "                   max_iter = 30000, display_iter=300, save_iter=1500, mode='rotation')\n",
    "######### Complete Tuning ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\"lr\": 3e-3, \"l2\":3e-3, \"iter\":30000}\n",
    "param_list.append(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decay 0.06, optimal hyperpara: lr: 3e-3, l2: 5e-3, 30k iter\n",
    "decay = 0.06\n",
    "learning_rate, weight_l2, weight_upper = 3e-3, 5e-3, 0\n",
    "X_toy = generate_toy_example(sample_size=1000, decay=decay)\n",
    "Y_toy = linear_model_generation(X_toy, beta_true)\n",
    "log_name = 'toy_decay_%.0e_l2_%.0e_lr_%.0e' % (decay, weight_l2, learning_rate)\n",
    "data_description = 'Toy data with decay %.0e' % (decay)\n",
    "variable_decorrelation(x = X_toy, y = Y_toy, log_name = log_name, data_description = data_description,\n",
    "                   learning_rate = learning_rate, weight_l2 = weight_l2, weight_upper = weight_upper, \n",
    "                   max_iter = 30000, display_iter=300, save_iter=1500, mode='rotation')\n",
    "######### Complete Tuning ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\"lr\": 3e-3, \"l2\":5e-3, \"iter\":30000}\n",
    "param_list.append(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decay 0.08, optimal hyperpara: lr: 3e-3, l2: 1e-2, 30k iter\n",
    "decay = 0.08\n",
    "learning_rate, weight_l2, weight_upper = 3e-3, 1e-2, 0\n",
    "X_toy = generate_toy_example(sample_size=1000, decay=decay)\n",
    "Y_toy = linear_model_generation(X_toy, beta_true)\n",
    "log_name = 'toy_decay_%.0e_l2_%.0e_lr_%.0e' % (decay, weight_l2, learning_rate)\n",
    "data_description = 'Toy data with decay %.0e' % (decay)\n",
    "variable_decorrelation(x = X_toy, y = Y_toy, log_name = log_name, data_description = data_description,\n",
    "                   learning_rate = learning_rate, weight_l2 = weight_l2, weight_upper = weight_upper, \n",
    "                   max_iter = 30000, display_iter=300, save_iter=1500, mode='rotation')\n",
    "######### Complete Tuning ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\"lr\": 3e-3, \"l2\":1e-2, \"iter\":30000}\n",
    "param_list.append(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decay 0.1, optimal hyperpara: lr: 3e-3, l2: 2e-2, 30k iter\n",
    "decay = 0.1\n",
    "learning_rate, weight_l2, weight_upper = 3e-3, 2e-2, 0\n",
    "X_toy = generate_toy_example(sample_size=1000, decay=decay)\n",
    "Y_toy = linear_model_generation(X_toy, beta_true)\n",
    "log_name = 'toy_decay_%.0e_l2_%.0e_lr_%.0e' % (decay, weight_l2, learning_rate)\n",
    "data_description = 'Toy data with decay %.0e' % (decay)\n",
    "variable_decorrelation(x = X_toy, y = Y_toy, log_name = log_name, data_description = data_description,\n",
    "                   learning_rate = learning_rate, weight_l2 = weight_l2, weight_upper = weight_upper, \n",
    "                   max_iter = 30000, display_iter=300, save_iter=1500, mode='rotation')\n",
    "######### Complete Tuning ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\"lr\": 3e-3, \"l2\":2e-2, \"iter\":30000}\n",
    "param_list.append(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decay 0.2, optimal hyperpara: lr: 1e-3 , l2: 5e-2, 30k iter\n",
    "decay = 0.2\n",
    "learning_rate, weight_l2, weight_upper = 1e-3, 5e-2, 0\n",
    "X_toy = generate_toy_example(sample_size=1000, decay=decay)\n",
    "Y_toy = linear_model_generation(X_toy, beta_true)\n",
    "log_name = 'toy_decay_%.0e_l2_%.0e_lr_%.0e' % (decay, weight_l2, learning_rate)\n",
    "data_description = 'Toy data with decay %.0e' % (decay)\n",
    "variable_decorrelation(x = X_toy, y = Y_toy, log_name = log_name, data_description = data_description,\n",
    "                   learning_rate = learning_rate, weight_l2 = weight_l2, weight_upper = weight_upper, \n",
    "                   max_iter = 30000, display_iter=300, save_iter=1500, mode='rotation')\n",
    "######### Complete Tuning ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\"lr\": 1e-3, \"l2\":5e-2, \"iter\":30000}\n",
    "param_list.append(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decay 1, optimal hyperpara: lr: 1e-4, l2:6e-1 , 60k iter\n",
    "decay = 1\n",
    "learning_rate, weight_l2, weight_upper = 1e-4, 6e-1, 0\n",
    "X_toy = generate_toy_example(sample_size=1000, decay=decay)\n",
    "Y_toy = linear_model_generation(X_toy, beta_true)\n",
    "log_name = 'toy_decay_%.0e_l2_%.0e_lr_%.0e' % (decay, weight_l2, learning_rate)\n",
    "data_description = 'Toy data with decay %.0e' % (decay)\n",
    "variable_decorrelation(x = X_toy, y = Y_toy, log_name = log_name, data_description = data_description,\n",
    "                   learning_rate = learning_rate, weight_l2 = weight_l2, weight_upper = weight_upper, \n",
    "                   max_iter = 60000, display_iter=300, save_iter=3000, mode='rotation')\n",
    "######### Complete Tuning ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\"lr\": 1e-4, \"l2\":6e-1, \"iter\":60000}\n",
    "param_list.append(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'lr': 0.003, 'l2': 0.0005, 'iter': 90000},\n",
       " {'lr': 0.003, 'l2': 0.0005, 'iter': 90000},\n",
       " {'lr': 0.003, 'l2': 0.001, 'iter': 30000},\n",
       " {'lr': 0.003, 'l2': 0.002, 'iter': 30000},\n",
       " {'lr': 0.003, 'l2': 0.003, 'iter': 30000},\n",
       " {'lr': 0.003, 'l2': 0.005, 'iter': 30000},\n",
       " {'lr': 0.003, 'l2': 0.01, 'iter': 30000},\n",
       " {'lr': 0.003, 'l2': 0.02, 'iter': 30000},\n",
       " {'lr': 0.001, 'l2': 0.05, 'iter': 30000},\n",
       " {'lr': 0.0001, 'l2': 0.6, 'iter': 60000}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.真实$\\beta$为（0.5, 0.5）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_true = np.array([[0], [1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_lasso = np.zeros((1, len(decay_list)))\n",
    "rmse_lasso_our = np.zeros((1, len(decay_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso()\n",
    "lasso_our = Lasso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "libgfortran.so.3: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-c0b2dc338005>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mX_toy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_toy_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mY_toy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_toy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m666\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mlasso\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_toy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_toy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'model/toy_l2/toy_decay_%.0e_l2_%.0e_lr_%.0e/model_iters%d.ckpt'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"l2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"iter\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Variable_Decorrelation/code/baseline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, validation, num_fold, val_metric, **options)\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# fit with glmnet with cross validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcvglmnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'gaussian'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mptype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnfolds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'default'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lambda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lambda_min'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/glmnet_python-0.2.0-py3.6.egg/glmnet_python/cvglmnet.py\u001b[0m in \u001b[0;36mcvglmnet\u001b[0;34m(x, y, family, ptype, nfolds, foldid, parallel, keep, grouped, **options)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;31m# main call to glmnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m     \u001b[0mglmfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglmnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0mis_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglmfit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'offset'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/glmnet_python-0.2.0-py3.6.egg/glmnet_python/glmnet.py\u001b[0m in \u001b[0;36mglmnet\u001b[0;34m(x, y, family, **options)\u001b[0m\n\u001b[1;32m    448\u001b[0m         fit = elnet(x, is_sparse, irs, pcs, y, weights, offset, gtype, parm, \n\u001b[1;32m    449\u001b[0m                     \u001b[0mlempty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnvars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mne\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mulam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m                     thresh, isd, intr, maxit, family)\n\u001b[0m\u001b[1;32m    451\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfamily\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'binomial'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfamily\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'multinomial'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0;31m# call lognet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/glmnet_python-0.2.0-py3.6.egg/glmnet_python/elnet.py\u001b[0m in \u001b[0;36melnet\u001b[0;34m(x, is_sparse, irs, pcs, y, weights, offset, gtype, parm, lempty, nvars, jd, vp, cl, ne, nx, nlam, flmin, ulam, thresh, isd, intr, maxit, family)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# load shared fortran library\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mglmlib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadGlmLib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# pre-process data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/glmnet_python-0.2.0-py3.6.egg/glmnet_python/loadGlmLib.py\u001b[0m in \u001b[0;36mloadGlmLib\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloadGlmLib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'posix'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mglmlib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglmnet_so\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglmlib\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nt'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/ctypes/__init__.py\u001b[0m in \u001b[0;36mLoadLibrary\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dlltype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0mcdll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLibraryLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: libgfortran.so.3: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "for ind, decay in enumerate(decay_list):\n",
    "    X_toy = generate_toy_example(sample_size=1000, decay=decay)\n",
    "    Y_toy = linear_model_generation(X_toy, beta_true, seed = 666)\n",
    "    lasso.fit(X_toy, Y_toy, intr = False)\n",
    "    param = param_list[ind]\n",
    "    model_path = 'model/toy_l2/toy_decay_%.0e_l2_%.0e_lr_%.0e/model_iters%d.ckpt' % (decay, param[\"l2\"],  param[\"lr\"], param[\"iter\"])\n",
    "    w = model.load_weight(X_toy, Y_toy, model_path)\n",
    "    lasso_our.fit(X_toy, Y_toy, weights = w, intr = False)\n",
    "    rmse_lasso[ind] = np.sqrt(np.mean(np.square(beta_true - lasso.beta)))\n",
    "    rmse_lasso_our[ind] = np.sqrt(np.mean(np.square(beta_true - lasso_our.beta)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.真实$\\beta$为（0， 1）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decay_list = [0.001, 0.01, 0.02, 0.03, 0.04, 0.06, 0.08, 0.1, 0.2, 1]\n",
    "beta_true = np.array([[0], [1.0]])\n",
    "learning_rate, weight_l2, weight_upper = 1e-5, 0.02, 0\n",
    "\n",
    "for ind, decay in enumerate(decay_list):\n",
    "    X_toy = generate_toy_example(sample_size=1000, decay=decay)\n",
    "    Y_toy = linear_model(X_toy, beta_true)\n",
    "    log_name = 'toy_decay_%.0e_l2_beta3' % (decay)\n",
    "    data_description = 'Toy data with decay %.0e and beta3' % (decay)\n",
    "    variable_decorrelation(x = X_toy, y = Y_toy, log_name = log_name, data_description = data_description,\n",
    "                       learning_rate = learning_rate, weight_l2 = weight_l2, weight_upper = weight_upper, \n",
    "                       max_iter = 30000, display_iter=300, save_iter=1500, mode='rotation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decay_list = [0.001, 0.01, 0.02, 0.03, 0.04, 0.06, 0.08, 0.1, 0.2, 1]\n",
    "beta_true = np.array([[0], [1.0]])\n",
    "rmse_beta3_lasso = np.zeros((1, len(decay_list))); rmse_beta3_decor = np.zeros((1, len(decay_list)))\n",
    "\n",
    "rmse_Y3_lasso = np.zeros((1, len(decay_list)))\n",
    "rmse_Y3_decor = np.zeros((1, len(decay_list)))\n",
    "rmse_Y3_true = np.zeros((1, len(decay_list)))\n",
    "\n",
    "std_Y3_lasso = np.zeros((1, len(decay_list)))\n",
    "std_Y3_decor = np.zeros((1, len(decay_list)))\n",
    "std_Y3_true = np.zeros((1, len(decay_list)))\n",
    "\n",
    "w_opt_list = np.zeros((1000, len(decay_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(); lasso_de = Lasso()\n",
    "_ = lasso.fit(x=X_toy, y=Y_toy, intr=False)\n",
    "_ = lasso_de.fit(x=X_toy, y=Y_toy, weights=w_opt, intr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lasso.beta, lasso_de.beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_beta3_lasso[0, ind] = lasso.cal_estimation_error(beta_true)\n",
    "rmse_beta3_decor[0, ind] = lasso_de.cal_estimation_error(beta_true)\n",
    "rmse_1 = []; rmse_2 = []; rmse_3 = []\n",
    "for indx, decay_test in enumerate(decay_list):\n",
    "    X_toy_test = generate_toy_example(sample_size=1000, decay=decay_test)\n",
    "    y_true = linear_model(X_toy_test, beta_true, seed = 666)#np.random.randint(0, 1000, 1))\n",
    "    rmse_1.append(lasso.cal_prediction_error(y_true = y_true,\n",
    "                                             y_predict = lasso.predict(X_toy_test)))\n",
    "    rmse_2.append(lasso_de.cal_prediction_error(y_true = y_true,\n",
    "                                                y_predict = lasso_de.predict(X_toy_test)))\n",
    "    rmse_3.append(np.sqrt(np.mean(np.square(y_true-np.matmul(X_toy_test, beta_true)))))\n",
    "rmse_Y3_lasso[0, ind] = np.mean(np.asarray(rmse_1))\n",
    "rmse_Y3_decor[0, ind] = np.mean(np.asarray(rmse_2))\n",
    "rmse_Y3_true[0, ind] = np.mean(np.asarray(rmse_3))\n",
    "std_Y3_lasso[0, ind] = np.std(np.asarray(rmse_1))\n",
    "std_Y3_decor[0, ind] = np.std(np.asarray(rmse_2))\n",
    "std_Y3_true[0, ind] = np.std(np.asarray(rmse_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6), dpi=100)\n",
    "plt.plot(decay_list, rmse_1,  color='red', linewidth=2.5, marker='o', label='Standard Lasso')\n",
    "plt.plot(decay_list, rmse_2,  color='green', linewidth=2.5, marker='x', label='Lasso with decorrelation')\n",
    "plt.vlines(x = decay_list[ind], ymin=min(rmse_2), ymax=0.8, linestyles='dashed', color='blue', label='Decay on training data')\n",
    "plt.legend(loc='upper left', frameon=False)\n",
    "plt.xlabel('Decay on test data', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Prediction Error (RMSE)', fontsize=12, fontweight='bold')\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_Y3_lasso, rmse_Y3_decor, rmse_Y3_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_Y3_lasso, std_Y3_decor, std_Y3_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6), dpi=100)\n",
    "plt.plot(decay_list, rmse_beta3_lasso.squeeze(), color='red', \n",
    "         linewidth=2.5, marker='o', label='Standard Lasso')\n",
    "plt.plot(decay_list, rmse_beta3_decor.squeeze(), color='green', \n",
    "         linewidth=2.5, marker='x', label='Lasso with decorrelation')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='upper right', frameon=False)\n",
    "plt.xlabel('Decay on training data', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Esimation Error (RMSE)', fontsize=12, fontweight='bold')\n",
    "plt.savefig('./figure/beta_toy_compare.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outcome Prediction and Stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "plt.figure(figsize=(12,8), dpi=100)\n",
    "# RMSE\n",
    "ax = plt.subplot(211)\n",
    "N = len(decay_list)\n",
    "ind = np.arange(N)    # the x locations for the groups\n",
    "width = 0.25         # the width of the bars\n",
    "plt.bar(ind, rmse_Y3_lasso.squeeze(), width, color='red', label='Standard Lasso')\n",
    "plt.bar(ind + width + 0.01, rmse_Y3_decor.squeeze(), width, color='green', label='Lasso with decorrelation')\n",
    "plt.hlines(y = 0.0994, xmin=-0.2, xmax=9.5, linestyles='dashed', color='blue', label='True Model')\n",
    "plt.legend(loc='upper right', frameon=False)\n",
    "ax.set_xticks(ind + width/2)\n",
    "ax.set_xticklabels(('0.001', '0.01', '0.02', '0.03', '0.04', '0.06', '0.08', '0.1', '0.2', '1'))\n",
    "plt.ylim(0.05, 0.22)\n",
    "plt.xlabel('Decay on training data', fontsize=12)\n",
    "plt.ylabel('Average RMSE', fontsize=12)\n",
    "# STD\n",
    "ax = plt.subplot(212)\n",
    "plt.bar(ind, std_Y3_lasso.squeeze(), width, color='red', label='Standard Lasso')\n",
    "plt.bar(ind + width + 0.01, std_Y3_decor.squeeze(), width, color='green', label='Lasso with decorrelation')\n",
    "plt.legend(loc='upper right', frameon=False)\n",
    "ax.set_xticks(ind + width/2)\n",
    "ax.set_xticklabels(('0.001', '0.01', '0.02', '0.03', '0.04', '0.06', '0.08', '0.1', '0.2', '1'))\n",
    "plt.xlabel('Decay on training data', fontsize=12)\n",
    "plt.ylabel('Stability (Std)', fontsize=12)\n",
    "plt.yscale('log')\n",
    "plt.savefig('./figure/Y_toy_compare.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the figure above, we can find:\n",
    "- Variable Decorrelation do help on parameter estimation and prediction when correlation is severe  \n",
    "\n",
    "We also notice the error of our method inflates when decay >= 0.08. To find out why, we inspect the optimal weights over different decay.  \n",
    "The standard deviation and maximum weight of optimal weight grow quickly with decay,  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.subplot(311)\n",
    "plt.plot(np.arange(10), np.std(w_opt_list, axis=0))\n",
    "plt.subplot(312)\n",
    "plt.plot(np.arange(10), np.max(w_opt_list, axis=0))\n",
    "plt.subplot(313)\n",
    "plt.plot(np.arange(10), np.sum(w_opt_list>5e-2, axis=0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exp2 - Synthetic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - 10 variables (2 groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decay_list = [0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decay 0.002, optimal hyperpara: lr: , l2: , k iter \n",
    "decay = 0.002\n",
    "X_group = data_generator.generate_group_data(sample_size = 1000, decay = 0.5, group_num = 2)\n",
    "Y_group = None\n",
    "\n",
    "learning_rate, weight_l2, weight_upper = 1e-3, 1e-2, 0\n",
    "log_name = 'group_decay_%.0e_l2_%.0e_lr_%.0e' % (decay, weight_l2, learning_rate)\n",
    "data_description = 'Group data (10 var) with decay %.0e' % (decay)\n",
    "variable_decorrelation(x = X_group, y = Y_group, log_name = log_name, data_description = data_description,\n",
    "                   learning_rate = learning_rate, weight_l2 = weight_l2, weight_upper = weight_upper, \n",
    "                   max_iter = 15000, display_iter=150, save_iter=1500, mode='rotation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(X[:,:5].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.random.normal(0,1,[10,2])\n",
    "b=np.matmul(a,np.array([0.4, 0.7]))  + np.random.normal(0,0.1,[10,])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=np.ones(10)\n",
    "mod_wls = sm.WLS(b, a, weights=w)\n",
    "res_wls = mod_wls.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_wls.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_wls.predict(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
